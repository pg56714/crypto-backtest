######################### å‰ç½®ä½œæ¥­ #########################
import pandas as pd
import numpy as np
import quantstats_lumi as qs
import os

# ========================
# åƒæ•¸è¨­å®š
# ========================
file_path = "crypto_historical_data.csv"  # æ­·å²æ•¸æ“šæª”æ¡ˆ
output_path = "backtest_results"  # å„²å­˜ç¸¾æ•ˆå ±å‘Šçš„è³‡æ–™å¤¾
timeframe = 12  # æ¯å€‹æ™‚é–“å–®ä½ç‚º12å°æ™‚
fraction = 0.0005  # äº¤æ˜“æˆæœ¬

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
os.makedirs(output_path, exist_ok=True)

# ========================
# è®€å–åƒ¹æ ¼è³‡æ–™
# ========================
print("ğŸ“Š æ­£åœ¨è®€å–æ­·å²åƒ¹æ ¼è³‡æ–™...")
price_df = pd.read_csv(file_path, index_col=0, parse_dates=True)
price_df = price_df.resample(f"{timeframe}h").last()
price_df.dropna(inplace=True)

# åˆ‡åˆ†è¨“ç·´è·Ÿæ¸¬è©¦çš„è³‡æ–™æ¯”ä¾‹
total_rows = len(price_df)
split_index = int(total_rows * 0.75)
training = price_df.copy().iloc[:split_index]
testing = price_df.copy().iloc[split_index:]

print(f"âœ… è¨“ç·´é›†ç¯„åœ: {training.index[0]} â†’ {training.index[-1]}")
print(f"âœ… æ¸¬è©¦é›†ç¯„åœ: {testing.index[0]} â†’ {testing.index[-1]}")


# ========================
# ç­–ç•¥é‚è¼¯
# ========================
def generate_returns(data, param):
    data_ret = data.pct_change().dropna()
    method_result = (
        (data_ret.rolling(param).sum()).rank(axis=1, ascending=False).dropna()
    )

    def transform_position(value):
        if value <= 4:
            return 1
        elif value >= len(data.columns) - 3:
            return -1
        else:
            return 0

    positions = method_result.map(transform_position)

    # ç­‰æ¬Šé‡åˆ†é…
    positions /= 8

    ret = data_ret * positions.shift(1) - fraction * np.abs(
        positions - positions.shift(1)
    )
    ret.dropna(inplace=True)
    ret["returns"] = ret.sum(axis=1)
    return ret, positions


# ========================
# èª¿æ•´åƒæ•¸ (Tuning Parameters)
# ========================
results = []

print("âš™ï¸ æ­£åœ¨èª¿æ•´ç­–ç•¥åƒæ•¸...")
for param in range(10, 200):
    returns, positions = generate_returns(training, param)
    sharpe = qs.stats.sharpe(returns["returns"], periods=365 * 24 / timeframe)
    results.append([param, sharpe])

results_df = pd.DataFrame(results, columns=["period", "sharpe"])
best_param = results_df.sort_values("sharpe", ascending=False).iloc[0]["period"]
print(f"ğŸ† æœ€ä½³åƒæ•¸: period = {best_param}")

# å„²å­˜åƒæ•¸èª¿æ•´çµæœ
results_df.to_csv(
    os.path.join(output_path, "parameter_tuning_results.csv"), index=False
)
print("âœ… åƒæ•¸èª¿æ•´çµæœå·²ä¿å­˜ã€‚")


# ========================
# è¨“ç·´é›†å›æ¸¬
# ========================
print("ğŸ“ˆ è¨“ç·´é›†å›æ¸¬ä¸­...")
returns_train, positions_train = generate_returns(training, int(best_param))
report_file_train = os.path.join(output_path, "training_report.html")
qs.reports.html(
    returns_train["returns"],
    output=report_file_train,
    title="Training Performance Report",
)
print(f"âœ… è¨“ç·´é›†ç¸¾æ•ˆå ±å‘Šå·²ç”Ÿæˆ: {report_file_train}")

# ========================
# æ¸¬è©¦é›†å›æ¸¬
# ========================
print("ğŸ“Š æ¸¬è©¦é›†å›æ¸¬ä¸­...")
returns_test, positions_test = generate_returns(testing, int(best_param))
report_file_test = os.path.join(output_path, "testing_report.html")
qs.reports.html(
    returns_test["returns"], output=report_file_test, title="Testing Performance Report"
)
print(f"âœ… æ¸¬è©¦é›†ç¸¾æ•ˆå ±å‘Šå·²ç”Ÿæˆ: {report_file_test}")

# ========================
# å…¨è³‡æ–™å›æ¸¬
# ========================
print("ğŸ“Š å…¨è³‡æ–™å›æ¸¬ä¸­...")
returns_full, positions_full = generate_returns(price_df, int(best_param))
report_file_full = os.path.join(output_path, "full_report.html")
qs.reports.html(
    returns_full["returns"],
    output=report_file_full,
    title="Full Data Performance Report",
)
print(f"âœ… å…¨è³‡æ–™ç¸¾æ•ˆå ±å‘Šå·²ç”Ÿæˆ: {report_file_full}")

# ========================
# é¡¯ç¤ºé‡è¦æŒ‡æ¨™
# ========================
print("ğŸ” è¨“ç·´é›†é—œéµç¸¾æ•ˆæŒ‡æ¨™ï¼š")
print(
    f"ğŸ“Š å¹´åŒ–å ±é…¬ç‡: {qs.stats.cagr(returns_train['returns'], periods=365*24/timeframe):.2%}"
)
print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {qs.stats.max_drawdown(returns_train['returns']):.2%}")
print(
    f"ğŸ“ˆ å¤æ™®æ¯”ç‡: {qs.stats.sharpe(returns_train['returns'], periods=365*24/timeframe):.2f}"
)

print("ğŸ” æ¸¬è©¦é›†é—œéµç¸¾æ•ˆæŒ‡æ¨™ï¼š")
print(
    f"ğŸ“Š å¹´åŒ–å ±é…¬ç‡: {qs.stats.cagr(returns_test['returns'], periods=365*24/timeframe):.2%}"
)
print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {qs.stats.max_drawdown(returns_test['returns']):.2%}")
print(
    f"ğŸ“ˆ å¤æ™®æ¯”ç‡: {qs.stats.sharpe(returns_test['returns'], periods=365*24/timeframe):.2f}"
)

print("ğŸ” å…¨è³‡æ–™é—œéµç¸¾æ•ˆæŒ‡æ¨™ï¼š")
print(
    f"ğŸ“Š å¹´åŒ–å ±é…¬ç‡: {qs.stats.cagr(returns_full['returns'], periods=365*24/timeframe):.2%}"
)
print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {qs.stats.max_drawdown(returns_full['returns']):.2%}")
print(
    f"ğŸ“ˆ å¤æ™®æ¯”ç‡: {qs.stats.sharpe(returns_full['returns'], periods=365*24/timeframe):.2f}"
)

print("ğŸš€ å›æ¸¬å®Œæˆï¼æ‰€æœ‰çµæœå·²ä¿å­˜è‡³æŒ‡å®šè³‡æ–™å¤¾ã€‚")
